{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 1: Data Acquisition\n",
    "\n",
    "Machine learning algorithms require **a lot** of data, typically the more the better. Of course, there are many pre-existing datasets available and often used for learning purposes, or as benchmarks for particular NLP tasks, such as SQuAD and GLUE. These datasets are often well studied and can simply be downloaded and used with minimal pre-processing.\n",
    "\n",
    "However, applying NLP to a new problem or task will often require data to be gathered, processed and if ground-truth labels are needed (e.g. for supervised learning), annotated. Indeed, the process of data acquisition can often be one of the most time consuming and labour intensive of any NLP project. Depending on the problem the data could come from existing documents, created by hand, or we can use the largest source of information - the internet. [Web scraping](https://en.wikipedia.org/wiki/Web_scraping) allows us to extract data from websites, so it is possible to obtain huge amounts of information. In fact, scraping was used to extract the ~500 billion token datasets used to train some of the largest SOTA language models, like GPT-3 ([Brown, T.B., et al. (2020)](https://papers.nips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf)).\n",
    "\n",
    "In this practical we will use web scraping to gather some movie reviews written by IMDB users. Specifically, from the [1001 Movies You Must See Before You Die (2020 Edition)](https://www.imdb.com/list/ls052535080/) list. Then, we will annotate these reviews with a sentiment, positive or negative. In later practicals we will learn how to process this data and then build a model to classify the sentiment.\n",
    "\n",
    "The objectives of this practical are:\n",
    "1. Understand the process of web scraping to obtain data\n",
    "\n",
    "2. Use existing tools to annotate data and manage data versioning\n",
    "\n",
    "3. Consider the legal and ethical implications of web scraping and data acquisition in general\n",
    "\n",
    "4. Produce a set of IMDB user reviews, annotated with positive or negative sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Import libraries\n",
    "\n",
    "Most of these Python libraries you should already be familiar with. For the web scraping we will use two specifially:\n",
    "\n",
    "1. Requests - allows us to make HTTP requests for web pages i.e. ask a web server to send a web page and its data.\n",
    "\n",
    "2. [Beautiful Soup 4 (bs4)](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) - is a Python library for parsing and navigating HTML files. This makes the job of finding the data we want, from within a recieved page, much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set the directory to the data folder\n",
    "data_dir = os.path.join('..', 'data', 'imdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Get a list of movie names and the URL to their IMDB page\n",
    "\n",
    "As previously stated, we will be getting reviews for movies in IMDB's curated list of [1001 Movies You Must See Before You Die (2020 Edition)](https://www.imdb.com/list/ls052535080/). If you follow the link you should can see the list of movies for yourself.\n",
    "\n",
    "The process of web scraping simply involves requesting a web page from a server and then extracting the data we are interested in. However, in reality we may not know the exact URL, or we may wish to scrape many web pages at once. In this case we have a list of movies and we need to find the links to each of their IMDB pages.\n",
    "\n",
    "1. First we send a request for the lists page. The response is the same information used by your browser to render the page. If you uncomment `print(response.content)` you can see the full response (it's pretty horrible) and `print(response.status_code)` tells us if it returned correctly or if there was an error.\n",
    "\n",
    "2. Next we use beautiful soup to parse the response into a more manageable object ('soup'). Again, if you uncomment `print(soup.prettify())` you can see what this looks like (better but still horrible).\n",
    "\n",
    "3. Now we can begin to parse the page's data to find the links to individual movies. If you opened the page in your browser you can right click on a movie title and select 'inspect'. This will open the developer console and you should see that each movie title is actually a link (`a` tag) to the movies page and each of these is held within a header (`h3` tag) of class `lister-item-header`. So we can use bs4 to get a list of all the headers of this class.\n",
    "\n",
    "4. Next we loop over all the movie headers get the name and link from within the `a` tags, then store it in a dictionary: keys = movie name, values = full URL.\n",
    "\n",
    "5. Finally print out the first 10 movies. You can see the movies all have a unique code at the end of the URL.\n",
    "\n",
    "\n",
    "<div class = \"alert alert-block alert-info\"><b>Note:</b> The list page only shows the first 100 of 1001 movies.<br>\n",
    "We could use pagination to get the rest, but let's just stick with 100 for now.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Trip to the Moon\thttps://www.imdb.com/title/tt0000417/\n",
      "The Great Train Robbery\thttps://www.imdb.com/title/tt0000439/\n",
      "The Birth of a Nation\thttps://www.imdb.com/title/tt0004972/\n",
      "Les vampires\thttps://www.imdb.com/title/tt0006206/\n",
      "Intolerance: Love's Struggle Throughout the Ages\thttps://www.imdb.com/title/tt0006864/\n",
      "The Cabinet of Dr. Caligari\thttps://www.imdb.com/title/tt0010323/\n",
      "Broken Blossoms\thttps://www.imdb.com/title/tt0009968/\n",
      "Within Our Gates\thttps://www.imdb.com/title/tt0011870/\n",
      "Orphans of the Storm\thttps://www.imdb.com/title/tt0012532/\n",
      "The Phantom Carriage\thttps://www.imdb.com/title/tt0012364/\n"
     ]
    }
   ],
   "source": [
    "# Base IMDB url and 1001 Movies You Must See Before You Die (2020 Edition) url\n",
    "imbd_url = 'https://www.imdb.com'\n",
    "list_url = 'https://www.imdb.com/list/ls052535080/'\n",
    "# header = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\"}\n",
    "\n",
    "# Send http request to get the list page\n",
    "response = requests.get(list_url)\n",
    "# print(response.status_code)\n",
    "# print(response.content)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "# print(soup.prettify())\n",
    "\n",
    "# Get the movie list\n",
    "# Inspecting the page we can see that the movie names are links to their pages\n",
    "# These header tags <h3> have the class \"lister-item-header\"\n",
    "mov_headers = soup.find_all('h3', {'class': 'lister-item-header'})\n",
    "\n",
    "# Now loop over the movies and store the name and link in a dictionary\n",
    "movies = OrderedDict()\n",
    "for h in mov_headers:\n",
    "    link = h.find('a', href=True)\n",
    "\n",
    "    # Movie name as key and link as value\n",
    "    # We append to the base IMDB url to get the full link, and discard the query string\n",
    "    movies[link.contents[0]] = imbd_url + link['href'].split('?')[0]\n",
    "\n",
    "# Now dispaly the first 10 movies\n",
    "for movie_name in list(movies.keys())[:10]:\n",
    "    print(movie_name + \"\\t\" + movies[movie_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Get the user reviews\n",
    "\n",
    "Now that we have the links for each movie we can get their reviews. You might expect movies in this list to have only positive reviews. However, #3 is highly controversial (and rightfully so) and has garnered some very negative reviews. For our purposes this means we will have a bit more balance between the sentiment classes. The process is similar to the previous step:\n",
    "\n",
    "1. Loop over each movie and request its review page (movie_url + \"reviews?\").\n",
    "\n",
    "2. Get the titles of the reviews and also the main texts.\n",
    "\n",
    "3. Store these in a list of dictionaries, along with a unique review id.\n",
    "\n",
    "4. Create a Dataframe to hold the movie id, name, url, review title and text and save as .csv.\n",
    "\n",
    "<div class = \"alert alert-block alert-info\"><b>Note:</b> The review page only shows the first 25 reviews.<br>\n",
    "Again, we could use pagination to get the rest, but let's just stick with 25 for now.\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<b>Legality of Web Scraping:</b> There are all kinds of <a href=https://www.blog.datahut.co/post/is-web-scraping-legal> legal and ethical considerations </a> surrounding web scraping, including copyright, scraping non-public data, or data behind a login, such as Facebook or Linkedin.<br>\n",
    "\n",
    "Notice that there is a time delay added after each movie request has been processed? This is to slow down the number of requests per second and prevent repeated requests overloading the server, or at least creating unnecessary traffic. Excessive 'crawl rates' could violate \"trespass to chattels\" law, though for this use case it is unlikely. Still, it is worth being polite while scraping.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-tt0000417</td>\n",
       "      <td>A Trip to the Moon</td>\n",
       "      <td>https://www.imdb.com/title/tt0000417/</td>\n",
       "      <td>Wonderfully imaginative and innovative\\n</td>\n",
       "      <td>A group of scientists build a rocket and fly t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-tt0000417</td>\n",
       "      <td>A Trip to the Moon</td>\n",
       "      <td>https://www.imdb.com/title/tt0000417/</td>\n",
       "      <td>I can now say that I've seen a movie that's o...</td>\n",
       "      <td>Georges Méliès's 1902 masterpiece is not just ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-tt0000417</td>\n",
       "      <td>A Trip to the Moon</td>\n",
       "      <td>https://www.imdb.com/title/tt0000417/</td>\n",
       "      <td>Narrative Development: Magic\\n</td>\n",
       "      <td>\"A Trip to the Moon\" is justly the most popula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-tt0000417</td>\n",
       "      <td>A Trip to the Moon</td>\n",
       "      <td>https://www.imdb.com/title/tt0000417/</td>\n",
       "      <td>Trip to the Moon, A\\n</td>\n",
       "      <td>Trip to the Moon, A (1902) **** (out of 4) aka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-tt0000417</td>\n",
       "      <td>A Trip to the Moon</td>\n",
       "      <td>https://www.imdb.com/title/tt0000417/</td>\n",
       "      <td>Tripping on the Moon.\\n</td>\n",
       "      <td>Since seeing nods to the landmark work in Mart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>20-tt0006864</td>\n",
       "      <td>Intolerance: Love's Struggle Throughout the Ages</td>\n",
       "      <td>https://www.imdb.com/title/tt0006864/</td>\n",
       "      <td>impressive for it's time as it is now, and ju...</td>\n",
       "      <td>The most remarkable thing about Intolerance wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>21-tt0006864</td>\n",
       "      <td>Intolerance: Love's Struggle Throughout the Ages</td>\n",
       "      <td>https://www.imdb.com/title/tt0006864/</td>\n",
       "      <td>MOST ADVENTUROUS MOVIE EVER MADE\\n</td>\n",
       "      <td>Only CITIZEN KANE and 2001:A SPACE ODYSSEY com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>22-tt0006864</td>\n",
       "      <td>Intolerance: Love's Struggle Throughout the Ages</td>\n",
       "      <td>https://www.imdb.com/title/tt0006864/</td>\n",
       "      <td>An Immortal Masterpiece. There's nothing in t...</td>\n",
       "      <td>Intolerance (1916) :\\nBrief Review -An Immorta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>23-tt0006864</td>\n",
       "      <td>Intolerance: Love's Struggle Throughout the Ages</td>\n",
       "      <td>https://www.imdb.com/title/tt0006864/</td>\n",
       "      <td>immense silent experience\\n</td>\n",
       "      <td>Four strands here, sometimes merging (as in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>24-tt0006864</td>\n",
       "      <td>Intolerance: Love's Struggle Throughout the Ages</td>\n",
       "      <td>https://www.imdb.com/title/tt0006864/</td>\n",
       "      <td>The Hand That Rocks The Cradle\\n</td>\n",
       "      <td>Although the messenger is a product of the 19t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                              name  \\\n",
       "0     0-tt0000417                                A Trip to the Moon   \n",
       "1     1-tt0000417                                A Trip to the Moon   \n",
       "2     2-tt0000417                                A Trip to the Moon   \n",
       "3     3-tt0000417                                A Trip to the Moon   \n",
       "4     4-tt0000417                                A Trip to the Moon   \n",
       "..            ...                                               ...   \n",
       "120  20-tt0006864  Intolerance: Love's Struggle Throughout the Ages   \n",
       "121  21-tt0006864  Intolerance: Love's Struggle Throughout the Ages   \n",
       "122  22-tt0006864  Intolerance: Love's Struggle Throughout the Ages   \n",
       "123  23-tt0006864  Intolerance: Love's Struggle Throughout the Ages   \n",
       "124  24-tt0006864  Intolerance: Love's Struggle Throughout the Ages   \n",
       "\n",
       "                                       url  \\\n",
       "0    https://www.imdb.com/title/tt0000417/   \n",
       "1    https://www.imdb.com/title/tt0000417/   \n",
       "2    https://www.imdb.com/title/tt0000417/   \n",
       "3    https://www.imdb.com/title/tt0000417/   \n",
       "4    https://www.imdb.com/title/tt0000417/   \n",
       "..                                     ...   \n",
       "120  https://www.imdb.com/title/tt0006864/   \n",
       "121  https://www.imdb.com/title/tt0006864/   \n",
       "122  https://www.imdb.com/title/tt0006864/   \n",
       "123  https://www.imdb.com/title/tt0006864/   \n",
       "124  https://www.imdb.com/title/tt0006864/   \n",
       "\n",
       "                                                 title  \\\n",
       "0             Wonderfully imaginative and innovative\\n   \n",
       "1     I can now say that I've seen a movie that's o...   \n",
       "2                       Narrative Development: Magic\\n   \n",
       "3                                Trip to the Moon, A\\n   \n",
       "4                              Tripping on the Moon.\\n   \n",
       "..                                                 ...   \n",
       "120   impressive for it's time as it is now, and ju...   \n",
       "121                 MOST ADVENTUROUS MOVIE EVER MADE\\n   \n",
       "122   An Immortal Masterpiece. There's nothing in t...   \n",
       "123                        immense silent experience\\n   \n",
       "124                   The Hand That Rocks The Cradle\\n   \n",
       "\n",
       "                                                review  \n",
       "0    A group of scientists build a rocket and fly t...  \n",
       "1    Georges Méliès's 1902 masterpiece is not just ...  \n",
       "2    \"A Trip to the Moon\" is justly the most popula...  \n",
       "3    Trip to the Moon, A (1902) **** (out of 4) aka...  \n",
       "4    Since seeing nods to the landmark work in Mart...  \n",
       "..                                                 ...  \n",
       "120  The most remarkable thing about Intolerance wh...  \n",
       "121  Only CITIZEN KANE and 2001:A SPACE ODYSSEY com...  \n",
       "122  Intolerance (1916) :\\nBrief Review -An Immorta...  \n",
       "123  Four strands here, sometimes merging (as in th...  \n",
       "124  Although the messenger is a product of the 19t...  \n",
       "\n",
       "[125 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get reviews for the first few movies\n",
    "# Alternatively you could get all movies (time consuming), or randomly select a subset\n",
    "num_movies = 5\n",
    "movie_reviews = []\n",
    "for movie_name in list(movies.keys())[:num_movies]:\n",
    "    \n",
    "    # Send http request to get the review page\n",
    "    # Appending \"reviews?\" to the movie url gets the review page\n",
    "    movie_url = movies[movie_name]\n",
    "    response = requests.get(movie_url + 'reviews?')\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Get the review titles\n",
    "    review_titles = soup.find_all('a', {'class': 'title'})\n",
    "    titles = [t.text for t in review_titles]\n",
    "\n",
    "    # Get the text of each review\n",
    "    review_contents = soup.find_all('div', {'class': 'text'})\n",
    "    reviews = [c.text for c in review_contents]\n",
    "\n",
    "    # Add to the list of reviews\n",
    "    for i, (title, review) in enumerate(zip(titles, reviews)):\n",
    "        id = str(i) + '-' + movie_url.split('/')[-2] # Create unique review id from the movie id\n",
    "        movie_reviews.append({'id': id,'name': movie_name, 'url': movie_url, 'title': title, 'review': review})\n",
    "\n",
    "    # Add a time delay to prevent excessive requests\n",
    "    time.sleep(random.randint(2, 5))\n",
    "\n",
    "# Create a dataframe from the list of reviews and save to csv\n",
    "reviews_df = pd.DataFrame(movie_reviews)\n",
    "reviews_df.to_csv('imdb_reviews_raw.csv')\n",
    "reviews_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: 1.3 Annotate sentiment labels for the reviews\n",
    "\n",
    "We are going to be analysing the sentiment of these reviews, so we need to add some sentiment labels. Later we can use these as an extra test set to evaluate a classifier. We could do this manually, but it is much simpler to use existing tools. In this case it is suggested you use [LightTag](https://www.lighttag.io/) which is a free text annotation tool. \n",
    "\n",
    "1. You can use your UWE email to create a free educational LightTag account.\n",
    "\n",
    "2. Following the LightTag introduction you can create an annotation schema with two classes 'positive' and 'negative'.\n",
    "\n",
    "3. Upload the `imdb_reviews_raw.csv` file and choose which field you want to annotate and create a job.\n",
    "\n",
    "4. You can also assign more annotators to your team. It is suggested you create a team for your group and share the workload. You should aim for ~100 reviews in total.\n",
    "\n",
    "5. Once you have finished assigning labels you can download the dataset as a JSON file and use the code below to merge the labels with the reviews dataframe we  created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\data\\\\imdb\\\\annotated_imdb_reviews.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ethan\\Documents\\GitHub\\AAI\\ICEBREAKER\\1_data_acquisition.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ethan/Documents/GitHub/AAI/ICEBREAKER/1_data_acquisition.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Open the JSON file and load the data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ethan/Documents/GitHub/AAI/ICEBREAKER/1_data_acquisition.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(data_dir, \u001b[39m'\u001b[39;49m\u001b[39mannotated_imdb_reviews.json\u001b[39;49m\u001b[39m'\u001b[39;49m)) \u001b[39mas\u001b[39;00m json_data:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ethan/Documents/GitHub/AAI/ICEBREAKER/1_data_acquisition.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(json_data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ethan/Documents/GitHub/AAI/ICEBREAKER/1_data_acquisition.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Loop over each example (movie review) getting the id and classification\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '..\\\\data\\\\imdb\\\\annotated_imdb_reviews.json'"
     ]
    }
   ],
   "source": [
    "# Open the JSON file and load the data\n",
    "with open(os.path.join(data_dir, 'annotated_imdb_reviews.json')) as json_data:\n",
    "    data = json.load(json_data)\n",
    "\n",
    "# Loop over each example (movie review) getting the id and classification\n",
    "classifications = []\n",
    "for example in data['examples']:\n",
    "    if example['classifications']:\n",
    "        classifications.append({'id': example['metadata'].get('id'), 'sentiment': example['classifications'][0]['classname']})\n",
    "\n",
    "# Create a dataframe from the classifications and merge with the reviews\n",
    "classes_df = pd.DataFrame(classifications)\n",
    "reviews_df = pd.read_csv(os.path.join(data_dir, 'imdb_reviews_raw.csv'), index_col=0)\n",
    "reviews_df = pd.merge(reviews_df, classes_df, on='id')\n",
    "\n",
    "# Save the annotated reviews\n",
    "reviews_df.to_csv(os.path.join(data_dir, 'imdb_reviews_raw.csv'))\n",
    "\n",
    "reviews_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "eda59365f9d652723e3bcf67739b9100ac1f6ab6ddfa121c8653940903b971a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
